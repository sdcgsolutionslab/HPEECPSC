{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A dive into a data scientist work \n",
    "\n",
    "The hands-on section will follow 3 main steps:\n",
    "\n",
    "  - **Prepare the groundwork**\n",
    "  \n",
    "  After importing the necessary dependencies, you will learn about what neural networks hyperparameters are, and what values we chose to assign to them. You will also perform a couple of transformations on the dataset to have it ready for the training.\n",
    "      \n",
    "    \n",
    "  - **Build and train your model**\n",
    "  \n",
    "  You will create a CNN based on architectural choices we made for you. You will be able to train the model and visualize some important metrics that guide a data scientist during the development cycle. Take the time to get familiar with the learning process that is common to different types of neural networks.\n",
    "   \n",
    "   \n",
    "  - **Evaluate and enhance the model**\n",
    " \n",
    " After visualizing the predictions made by the model on some handwritten digit images, you will have the opportunity to adjust the neural network and get better predictions. For this, you can tune the hyperparameters and the architecture of the neural network to increase its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the groundwork\n",
    "\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use Keras, a high level API for Tensorflow to design and train your first simple CNN. \n",
    "Frameworks like Tensorflow, Pytorch,etc. are practical to hide the computational complexity that the forward and backpropagation bring for instance. The coding effort is then focused on designing deep and complex neural network architectures, exploring creative metrics to make the training more efficient, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist #28x28 images\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are handling dataset where each image is a 28x28 pixels wide handwritten digit. \n",
    "\n",
    "Each input image being categorized to a '0' to '9' class, we have a total of 10 classes.\n",
    "\n",
    "<img src=\"https://huchma.fi/wp-content/posts_material/001/mnist/mnist.png\" width=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# numbers of predictable classes, from 0 to 9\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters:\n",
    "\n",
    "While the gradient descent with forward and backpropagation helps to learn the parameters of a neural network, the hyperparameters are a set of non learnable parameters that still have a big impact on the accuracy one can reach after the training. They will then directly impact the performance of the model.\n",
    "\n",
    "To visualize the hyperparameters you can refer to the CNN layout below:\n",
    "\n",
    "\n",
    "<img src=\"illustration/new network.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Here a predefined list we suggest to start with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Hyperparameters\n",
    "#################\n",
    "batch_size = 8\n",
    "nb_epoch = 1\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 10\n",
    "# number of neurons in the dense layers\n",
    "nb_dense_layer_1 = 40\n",
    "nb_dense_layer_2 = 10\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "dropout_rate = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a description to better understand what they represent:\n",
    "    - Epoch : a complete pass over the entire dataset in the training phase\n",
    "    - Batch : a subset of the dataset over which the loss is calculated to perform a single gradient descent step\n",
    "    - Convolutional filters (or kernel) number and size :\n",
    "<img src=\"https://d2l.ai/_images/conv-pad.svg\" width=\"300\" align=\"center\"/>\n",
    "                \n",
    "                image source: https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html\n",
    "\n",
    "    - Pooling size:\n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-98ecf7ba49710bf56042d035a74505b6\" width=\"250\" align=\"center\"/> \n",
    "                \n",
    "                image source:quora.com/What-is-max-pooling-in-convolutional-neural-networks\n",
    "                \n",
    "    - Dropout: a regularization technique that helps preventing neural networks from overfitting.\n",
    "\n",
    "<img src=\"illustration/bootstrap-aggregating-img2.png\" width=\"550\" align=\"center\"/>\n",
    "\n",
    "                image source:\"DEEP LEARNING BOOK â€“ IAN GOODFELLOW AND YOSHUA BENGIO AND AARON COURVILLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "The dataset is always split at least into training and test data:\n",
    "  - **60.000 images used to train** the neural network. Every image will be passed through the CNN to teach the network and update the parameters following the learning process\n",
    "  \n",
    "  - **10.000 images used to test** the accuracy of the network. This subset is never seen by the network during the training. It then represents how the model would behave with real life data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('Training data is composed of', X_train.shape[0], 'samples of', X_train.shape[1], 'x', X_train.shape[2], 'grayscale images')\n",
    "print('Test data is composed of', X_test.shape[0], 'samples of', X_test.shape[1], 'x', X_test.shape[2], 'grayscale images\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Other steps are necessary before starting the training process. Here are some examples:\n",
    "\n",
    "    - Normalization for a more stable and fast learning\n",
    "    - Label transformation to move to a one hot vector representation of the classes. \n",
    "    A one hot vector representation (see image below) transforms a one value label to a vector with 10 elements. '1' is set for the element with the index corresponding to the label value (5th element when the digit is '5' for instance), and '0' elsewhere.\n",
    "    The network will thus make a prediction of a vector with 10 values, each corresponding to one of the 10 classes. It will express the probability that the picture belongs to each of the classes, showing (hopefully) more confidence on the right class, through a higher probability value.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/wKtY1Og.png\" width=\"400\" align=\"center\"/> \n",
    "\n",
    "                image source:https://www.pluralsight.com/guides/getting-started-tensorflow\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalization\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices (one hot vector encoding)\n",
    "first_element = Y_train[0]\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, nb_classes)\n",
    "print('Y_train shape after moving to categorical representation:', Y_train.shape,'\\n')\n",
    "print('First element in Y_train is a :',first_element)\n",
    "print('First element Y_train after transformation :', Y_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train your model\n",
    "\n",
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can recognize the model from the representation below:\n",
    "\n",
    "<img src=\"illustration/new network.png\" width=\"500\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mycnn():\n",
    "    myinput = tf.keras.Input(shape=input_shape)\n",
    "    # Convolution layers\n",
    "    x = tf.keras.layers.Conv2D(nb_filters, kernel_size, strides=(1,1), padding='same', activation=tf.nn.relu)(myinput)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size, pool_size, padding='same')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(nb_dense_layer_1, activation = tf.nn.relu)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(nb_dense_layer_2, activation = tf.nn.softmax)(x)\n",
    "    model = tf.keras.Model(inputs=myinput, outputs=x)        \n",
    "    \n",
    "    return model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mymodel = mycnn()\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mymodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "history = mymodel.fit(X_train, Y_train,\n",
    "                    epochs=nb_epoch, batch_size=batch_size,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training is a long process, you might have noticed that the training was only performed for **1 epoch**. Usually the number of epochs would be higher than that.\n",
    "\n",
    "You can see below a graph showing the evolution of loss and accuracy for a **12 epochs training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist=pd.read_csv('models/history_cnn_12_epochs.csv')\n",
    "plt.plot(df_hist['acc'])\n",
    "plt.plot(df_hist['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.read_csv('models/history_cnn_12_epochs.csv')\n",
    "plt.plot(df_hist['loss'])\n",
    "plt.plot(df_hist['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and enhance the model\n",
    "\n",
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = mymodel.evaluate(X_test, Y_test)\n",
    "print('Test loss after 1 epoch training:', res[0])\n",
    "print('Test accuracy after 1 epoch training:', res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"./samples\"):\n",
    "    if filename.endswith(\".jpg\"): \n",
    "        wholename = \"./samples\" + \"/\" + filename\n",
    "        img = load_img(wholename, False, target_size = (28, 28))\n",
    "        x = img_to_array(img)\n",
    "        x1 = x[:, :, 1]\n",
    "        x1 = np.expand_dims(x1, axis = 2)\n",
    "        x1 = np.expand_dims(x1, axis = 0)\n",
    "        label = -1\n",
    "        plt.title('Original Label %d' % (label) )\n",
    "        plt.imshow(x1.reshape([28,28]), cmap=plt.get_cmap('gray'))\n",
    "        plt.show()\n",
    "        prob = mymodel.predict(x1) \n",
    "        pred = prob.argmax(axis=-1)\n",
    "        print('pred', pred, 'prob', prob)\n",
    "        print(\"------------------------------\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a better model\n",
    "\n",
    "You have been able to create and train a first simple CNN to recognize hand written digits. As you have noticed, its performance is still to be enhanced and this will be the purpose of this section.\n",
    "\n",
    "Below you can view the performance with a model we trained increasing the number of epochs and changing some hyperparameters like the number of dense layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a pretrained good model we prepared for you\n",
    "\n",
    "six_epochs_model = tf.keras.models.load_model('models/cnn_6epochs.h5')\n",
    "six_epochs_score = six_epochs_model.evaluate(X_test, Y_test)\n",
    "print('Test loss after 6 epochs training:', six_epochs_score[0])\n",
    "print('Test accuracy after 6 epochs training:', six_epochs_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can try to increase the performance following **some** of these hints:\n",
    "* Changing the dropout value (hint: read the tensorflow warning)\n",
    "* Increasing the batch size\n",
    "* Increasing the number of epochs\n",
    "* Increasing the number of neurons in the dense layer\n",
    "* Increasing the number of conv filters\n",
    "* Changing the filter size to 5x5, or adding extra conv layers\n",
    "* etc.\n",
    "\n",
    "Check the number of parameters and the accuracy of the training and validation/test set. You can also inspect the prediction on some of the samples under 'images' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set SOME new values here\n",
    "#################\n",
    "# Hyperparameters\n",
    "#################\n",
    "batch_size = 8\n",
    "nb_epoch = 1\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 10\n",
    "# number of neurons in the dense layers\n",
    "nb_dense_layer_1 = 40\n",
    "nb_dense_layer_2 = 10\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# Check the tensorflow warning, dropout value might be too high\n",
    "dropout_rate = 0.9\n",
    "\n",
    "def my_new_cnn():\n",
    "    myinput = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(nb_filters, kernel_size, strides=(1,1), padding='same', activation=tf.nn.relu)(myinput)\n",
    "    # hint: maybe an additional Conv layer ?\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size, pool_size, padding='same')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(nb_dense_layer_1, activation = tf.nn.relu)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(nb_dense_layer_2, activation = tf.nn.softmax)(x)\n",
    "    model = tf.keras.Model(inputs=myinput, outputs=x)        \n",
    "    \n",
    "    return model\n",
    "\n",
    "my_new_model = my_new_cnn()\n",
    "my_new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "history = my_new_model.fit(X_train, Y_train,\n",
    "                    epochs=nb_epoch, batch_size=batch_size,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"./samples\"):\n",
    "    if filename.endswith(\".jpg\"): \n",
    "        wholename = \"./samples\" + \"/\" + filename\n",
    "        img = load_img(wholename, False, target_size = (28, 28))\n",
    "        x = img_to_array(img)\n",
    "        x1 = x[:, :, 1]\n",
    "        x1 = np.expand_dims(x1, axis = 2)\n",
    "        x1 = np.expand_dims(x1, axis = 0)\n",
    "        label = -1\n",
    "        plt.title('Original Label %d' % (label) )\n",
    "        plt.imshow(x1.reshape([28,28]), cmap=plt.get_cmap('gray'))\n",
    "        plt.show()\n",
    "        prob = my_new_model.predict(x1) \n",
    "        pred = prob.argmax(axis=-1)\n",
    "        print('pred', pred, 'prob', prob)\n",
    "        print(\"------------------------------\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations!  \n",
    "\n",
    "You have not only trained a simple CNN, but you have also learned to improve the performance of the model. This concludes our lab portion. \n",
    "\n",
    "You can now proceed to the Conclusion notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
